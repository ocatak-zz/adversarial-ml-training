{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Machine Learning Mitigation: *Adversarial Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several attacks against deep learning models in the literature, including **fast-gradient sign method** (FGSM), **basic iterative method** (BIM) or **momentum iterative method** (MIM) attacks. These attack are the purest form of the gradient-based evading technique that is used by attackers to evade the classification model. \n",
    "\n",
    "## Cite The Code\n",
    "If you find those results useful please cite this paper :\n",
    "```\n",
    "    @PROCEEDINGS{catak-adv-ml-2020,\n",
    "    title = {Deep Neural Network based Malicious Network Activity Detection Under Adversarial Machine Learning Attacks},\n",
    "    booktitle = {Proc.\\ 3rd International Conference on Intelligent Technologies and Applications (INTAP 2020)},\n",
    "    volume = 5805,\n",
    "    series = {LNCS},\n",
    "    publisher = {Springer},\n",
    "    year = {2020}\n",
    "    }\n",
    "```\n",
    "## Introduction\n",
    "In this work, I will present a new approach to protect a malicious activity detection model from the several adversarial machine learning attacks. Hence, we explore the power of applying adversarial training to build a robust model against FGSM attacks. Accordingly, (1) dataset enhanced with the adversarial examples; (2) deep neural network-based detection model is trained using the KDDCUP99 dataset to learn the FGSM based attack patterns. We applied this training model to the benchmark cyber security dataset.\n",
    "\n",
    "The adversarial machine learning has been used to describe the attacks to machine learning models, which tries to mislead models by malicious input instances. Figure shows the typical adversarial machine learning attack.\n",
    "\n",
    "![Adversarial machine learning attack](adversarial_attack.png)\n",
    "\n",
    "A typical machine learning model basically consists of two stages as training time and decision time. Thus, the adversarial machine learning attacks occur in either training time or decision time. The techniques used by hackers for adversarial machine learning can be divided into two, according to the time of the attack:\n",
    "\n",
    "* **Data Poisoning**: The attacker changes some labels of training input instances to mislead the output model.\n",
    "* **Model Poisoning**: The hacker drives model to produce false labeling using some perturbated instance after the model is created.\n",
    "\n",
    "Our model is able to respond to the model attacks by hackers who use the adversarial machine learning methods. Figure illustrates the system architecture used to protect the model and to classify correctly.\n",
    "![Adversarial machine learning attack mitigation](adversarial-machine-learning-mitigation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's coding\n",
    "We import the usual standard libraries plus one cleverhans library to make adversarial attack to the deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_kddcup99\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from cleverhans.future.tf2.attacks import fast_gradient_method, \\\n",
    "    basic_iterative_method, momentum_iterative_method\n",
    "\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work, we will use standart KDDCUP'99 intrusion detection dataset to show the results. We need to extract the numerical features from the dataset. I created a new method to load and extract the KDDCUP'99 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_NAME = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
    "            'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
    "            'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
    "            'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
    "            'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "            'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "            'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate',\n",
    "            'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
    "            'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
    "            'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "            'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
    "            'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n",
    "\n",
    "NUMERIC_COLS = ['duration', 'src_bytes', 'dst_bytes', 'wrong_fragment',\n",
    "                'urgent', 'hot', 'num_failed_logins', 'num_compromised',\n",
    "                'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
    "                'num_shells', 'num_access_files', 'num_outbound_cmds', 'count',\n",
    "                'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate',\n",
    "                'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "                'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "                'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "                'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "                'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "                'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n",
    "\n",
    "def get_ds():\n",
    "    \"\"\" get_ds: Get the numeric values of the KDDCUP'99 dataset. \"\"\"\n",
    "    x_kddcup, y_kddcup = fetch_kddcup99(return_X_y=True, shuffle=False)\n",
    "    df_kddcup = pd.DataFrame(x_kddcup, columns=COL_NAME)\n",
    "    df_kddcup['label'] = y_kddcup\n",
    "    df_kddcup.drop_duplicates(keep='first', inplace=True)\n",
    "    df_kddcup['label'] = df_kddcup['label'].apply(lambda d: \\\n",
    "                                    str(d).replace('.', '').replace(\"b'\", \"\").\\\n",
    "                                        replace(\"'\", \"\"))\n",
    "\n",
    "    conversion_dict = {'back':'dos', 'buffer_overflow':'u2r', 'ftp_write':'r2l',\n",
    "                       'guess_passwd':'r2l', 'imap':'r2l', 'ipsweep':'probe',\n",
    "                       'land':'dos', 'loadmodule':'u2r', 'multihop':'r2l',\n",
    "                       'neptune':'dos', 'nmap':'probe', 'perl':'u2r', 'phf':'r2l',\n",
    "                       'pod':'dos', 'portsweep':'probe', 'rootkit':'u2r',\n",
    "                       'satan':'probe', 'smurf':'dos', 'spy':'r2l', 'teardrop':'dos',\n",
    "                       'warezclient':'r2l', 'warezmaster':'r2l'}\n",
    "    df_kddcup['label'] = df_kddcup['label'].replace(conversion_dict)\n",
    "    df_kddcup = df_kddcup.query(\"label != 'u2r'\")\n",
    "    df_y = pd.DataFrame(df_kddcup.label, columns=[\"label\"], dtype=\"category\")\n",
    "    df_kddcup.drop([\"label\"], inplace=True, axis=1)\n",
    "    x_kddcup = df_kddcup[NUMERIC_COLS].values\n",
    "    x_kddcup = preprocessing.scale(x_kddcup)\n",
    "    y_kddcup = df_y.label.cat.codes.to_numpy()\n",
    "    return x_kddcup, y_kddcup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflow based classification model is then given for example as exercise here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_model(input_size, num_of_class):\n",
    "    \"\"\" This method creates the tensorflow classification model \"\"\"\n",
    "    model_kddcup = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(200, input_dim=input_size, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(500, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(200, activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dense(num_of_class),\n",
    "        # We seperate the activation layer to be able to access\n",
    "        # the logits of the previous layer later\n",
    "        tf.keras.layers.Activation(tf.nn.softmax)\n",
    "        ])\n",
    "    model_kddcup.compile(loss='categorical_crossentropy',\n",
    "                         optimizer='adam',\n",
    "                         metrics=['accuracy'])\n",
    "    return model_kddcup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create adversarial machine learning attacks using CleverHans library. I used **fast-gradient sign method** (FGSM), **basic iterative method** (BIM) or **momentum iterative method** (MIM) attacks for the Tensorflow library. I created 3 methods for each attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tf2_fgsm_attack(org_model, x_test):\n",
    "    \"\"\" This method creates adversarial examples with fgsm \"\"\"\n",
    "    logits_model = tf.keras.Model(org_model.input, model.layers[-1].output)\n",
    "\n",
    "    epsilon = 0.1\n",
    "    adv_fgsm_x = fast_gradient_method(logits_model,\n",
    "                                      x_test,\n",
    "                                      epsilon,\n",
    "                                      np.inf,\n",
    "                                      targeted=False)\n",
    "    return adv_fgsm_x\n",
    "\n",
    "def gen_tf2_bim(org_model, x_test):\n",
    "    \"\"\" This method creates adversarial examples with bim \"\"\"\n",
    "    logits_model = tf.keras.Model(org_model.input, model.layers[-1].output)\n",
    "\n",
    "    epsilon = 0.1\n",
    "    adv_bim_x = basic_iterative_method(logits_model,\n",
    "                                       x_test,\n",
    "                                       epsilon,\n",
    "                                       0.1,\n",
    "                                       nb_iter=10,\n",
    "                                       norm=np.inf,\n",
    "                                       targeted=True)\n",
    "    return adv_bim_x\n",
    "\n",
    "def gen_tf2_mim(org_model, x_test):\n",
    "    \"\"\" This method creates adversarial examples with mim \"\"\"\n",
    "    logits_model = tf.keras.Model(org_model.input, model.layers[-1].output)\n",
    "\n",
    "    epsilon = 0.1\n",
    "    adv_mim_x = momentum_iterative_method(logits_model,\n",
    "                                          x_test,\n",
    "                                          epsilon,\n",
    "                                          0.1,\n",
    "                                          nb_iter=100,\n",
    "                                          norm=np.inf,\n",
    "                                          targeted=True)\n",
    "    return adv_mim_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with the training of the attack detection model with the normal (non-manipulated) KDDCUP'99 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferhatoc\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000025288139948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000025288139948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025287FF4318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025287FF4318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From <ipython-input-7-6c756bab0648>:24: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025283D0E798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025283D0E798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "**************************************************\n",
      "Original confusion matrix\n",
      "[[10873    16     0     0]\n",
      " [   16 17528     6    18]\n",
      " [    7    20   403    11]\n",
      " [    3    23     4   179]]\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 50\n",
    "TEST_RATE = 0.2\n",
    "VALIDATION_RATE = 0.2\n",
    "\n",
    "X, y = get_ds()\n",
    "\n",
    "num_class = len(np.unique(y))\n",
    "\n",
    "attack_functions = [gen_tf2_bim,\n",
    "                    gen_tf2_fgsm_attack,\n",
    "                    gen_tf2_mim]\n",
    "\n",
    "model = create_tf_model(X.shape[1], num_class)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "                                                    test_size=TEST_RATE)\n",
    "y_train_cat = np_utils.to_categorical(y_train)\n",
    "y_test_cat = np_utils.to_categorical(y_test)\n",
    "\n",
    "history = model.fit(X_train, y_train_cat, epochs=EPOCH,\n",
    "                    batch_size=50000, verbose=0,\n",
    "                    validation_split=VALIDATION_RATE)\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "cm_org = confusion_matrix(y_test, y_pred)\n",
    "print(\"*\"*50)\n",
    "print(\"Original confusion matrix\")\n",
    "print(cm_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Model's Confusion Matrix\n",
    "The original model's confusion matrix is shown here. According to the confusion matrix, the model's classification performance quite good.\n",
    "\n",
    "|  |  |  |  |\n",
    "| :-------| :-----: | ------: | ------: |\n",
    "|  10873  | 16      | 0       | 0       |\n",
    "| 16      | 17528   | 6       | 18      |\n",
    "|    7    | 20      | 403     |  11     |\n",
    "|    3    | 23      |  4      | 179     |\n",
    "\n",
    "Let's continue with the attacks, attacked model's confusion matrices and adversarial trained model's confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Attack function is  <function gen_tf2_bim at 0x00000252FCF84A68>\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000252FD05FDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000252FD05FDC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000252877B80D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000252877B80D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025281E8B168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025281E8B168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "********************\n",
      "Attacked confusion matrix\n",
      "[[10874    15     0     0]\n",
      " [   14 17532     7    15]\n",
      " [    6    19   404    12]\n",
      " [    3    23     5   178]]\n",
      "Adversarial training\n",
      "********************\n",
      "Attacked confusion matrix - adv training\n",
      "[[10877    12     0     0]\n",
      " [   12 17535     6    15]\n",
      " [    1    13   425     2]\n",
      " [    0    22     3   184]]\n",
      "********************\n",
      "Attack function is  <function gen_tf2_fgsm_attack at 0x00000252FCF84B88>\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000025281E8B438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000025281E8B438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025288BB38B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000025288BB38B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025287EF2558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025287EF2558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "********************\n",
      "Attacked confusion matrix\n",
      "[[10702   180     6     1]\n",
      " [   79 17353    31   105]\n",
      " [    9    47   376     9]\n",
      " [    3    88     8   110]]\n",
      "Adversarial training\n",
      "********************\n",
      "Attacked confusion matrix - adv training\n",
      "[[10877    11     0     1]\n",
      " [    9 17543     4    12]\n",
      " [    1    15   422     3]\n",
      " [    2    25     2   180]]\n",
      "********************\n",
      "Attack function is  <function gen_tf2_mim at 0x00000252FCF84D38>\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000252875459D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000252875459D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000252F9990048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000252F9990048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function compute_gradient at 0x00000252FCF6A318> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025280355A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000025280355A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "********************\n",
      "Attacked confusion matrix\n",
      "[[10874    15     0     0]\n",
      " [   16 17530     5    17]\n",
      " [    6    24   400    11]\n",
      " [    3    23     5   178]]\n",
      "Adversarial training\n",
      "********************\n",
      "Attacked confusion matrix - adv training\n",
      "[[10878    11     0     0]\n",
      " [   12 17537     4    15]\n",
      " [    1    16   420     4]\n",
      " [    0    21     2   186]]\n"
     ]
    }
   ],
   "source": [
    "for attack_function in attack_functions:\n",
    "        print(\"*\"*20)\n",
    "        print(\"Attack function is \", attack_function)\n",
    "        \n",
    "        model = create_tf_model(X.shape[1], num_class)\n",
    "        history = model.fit(X_train, y_train_cat, epochs=EPOCH,\n",
    "                            batch_size=50000, verbose=0,\n",
    "                            validation_split=VALIDATION_RATE)\n",
    "        \n",
    "        X_adv_list = []\n",
    "        y_adv_list = []\n",
    "\n",
    "        adv_x = attack_function(model, X_test)\n",
    "        y_pred = model.predict_classes(adv_x)\n",
    "        cm_adv = confusion_matrix(y_test, y_pred)\n",
    "        print(\"*\"*20)\n",
    "        print(\"Attacked confusion matrix\")\n",
    "        print(cm_adv)\n",
    "\n",
    "        print(\"Adversarial training\")\n",
    "        # define the checkpoint\n",
    "\n",
    "        adv_x = attack_function(model, X_train)\n",
    "        adv_x_test = attack_function(model, X_test)\n",
    "\n",
    "        concat_adv_x = np.concatenate([X_train, adv_x])\n",
    "        concat_y_train = np.concatenate([y_train_cat, y_train_cat])\n",
    "\n",
    "        history = model.fit(concat_adv_x, concat_y_train, epochs=EPOCH,\n",
    "                            batch_size=50000, verbose=0,\n",
    "                            validation_data=(adv_x_test, y_test_cat))\n",
    "\n",
    "        y_pred = model.predict_classes(adv_x_test)\n",
    "        cm_adv = confusion_matrix(y_test, y_pred)\n",
    "        print(\"*\"*20)\n",
    "        print(\"Attacked confusion matrix - adv training\")\n",
    "        print(cm_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Trainings Results\n",
    "### Basic Iterative Method (BIM)\n",
    "Attacked model's confusion matrix\n",
    "\n",
    "|  |  |  |  |\n",
    "| :-------| :-----: | ------: | ------: |\n",
    "|  10874  | 15      | 0       | 0       |\n",
    "| 14      | 17532   | 7       | 15      |\n",
    "|    6    | 19      | 404     |  12     |\n",
    "|    3    | 23      |  5      | 178     |\n",
    "\n",
    "Adversarial trained model's confusion matrix\n",
    "\n",
    "|  |  |  |  |\n",
    "| :-------| :-----: | ------: | ------: |\n",
    "|  10877  | 12      | 0       | 0       |\n",
    "| 12      | 17535   | 6       | 15      |\n",
    "|    1    | 13      | 425     |   2     |\n",
    "|    0    | 22      |  3      | 184     |\n",
    "\n",
    "### Fast Gradient Sign Method (FGSM)\n",
    "Attacked model's confusion matrix\n",
    "\n",
    "|  |  |  |  |\n",
    "| :-------| :-----: | ------: | ------: |\n",
    "|  10702  | 180     | 6       | 1       |\n",
    "| 79      | 17353   | 31      | 105     |\n",
    "|    9    | 47      | 376     |  9      |\n",
    "|    3    | 88      |  8      | 110     |\n",
    "\n",
    "Adversarial trained model's confusion matrix\n",
    "\n",
    "|  |  |  |  |\n",
    "| :-------| :-----: | ------: | ------: |\n",
    "|  10877  | 11      | 0       | 1       |\n",
    "| 9       | 17543   | 4       | 12      |\n",
    "|    1    | 15      | 422     |   3     |\n",
    "|    2    | 25      |  2      | 180     |\n",
    "\n",
    "### Momentum Iterative Method (MIM)\n",
    "Attacked model's confusion matrix\n",
    "\n",
    "|  |  |  |  |\n",
    "| :-------| :-----: | ------: | ------: |\n",
    "|  10874  | 15      | 0       | 0       |\n",
    "| 16      | 17530   | 5       | 17      |\n",
    "|    6    | 24      | 400     |  11      |\n",
    "|    3    | 23      |  5      | 178     |\n",
    "\n",
    "Adversarial trained model's confusion matrix\n",
    "\n",
    "|  |  |  |  |\n",
    "| :-------| :-----: | ------: | ------: |\n",
    "|  10878  | 11      | 0       | 0       |\n",
    "| 12      | 17537   | 4       | 15      |\n",
    "|    1    | 16      | 420     |   4     |\n",
    "|    0    | 21      |  2      | 186     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
